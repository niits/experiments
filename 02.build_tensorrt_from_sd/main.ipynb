{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -e custom-diffusers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from custom_diffusers import UNet2DConditionModel\n",
    "from diffusers import DiffusionPipeline, StableDiffusionPipeline\n",
    "from optimum.exporters.onnx import export\n",
    "from optimum.onnxruntime import ORTStableDiffusionPipeline\n",
    "from pathlib import Path\n",
    "import onnx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_DIR = Path(\"./exported-models/torch\")\n",
    "\n",
    "TORCH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "ONNX_DIR = Path(\"./exported-models/onnx\")\n",
    "\n",
    "ONNX_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = DiffusionPipeline.from_pretrained(\n",
    "#     MODEL_ID,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     use_safetensors=True,\n",
    "# )\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "# image = pipe(prompt).images[0]\n",
    "\n",
    "\n",
    "# pipe.save_pretrained(TORCH_DIR / \"stable-diffusion-v1-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export models to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = ONNX_DIR / \"stable-diffusion-v1-5\"\n",
    "\n",
    "if not SAVE_PATH.exists():\n",
    "    try:\n",
    "\n",
    "        SAVE_PATH.mkdir(parents=True)\n",
    "        pipeline = ORTStableDiffusionPipeline.from_pretrained(MODEL_ID, export=True)\n",
    "        pipeline.save_pretrained(SAVE_PATH.as_posix())\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        SAVE_PATH.rmdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = ORTStableDiffusionPipeline.from_pretrained(\n",
    "#     SAVE_PATH.as_posix(),\n",
    "# )\n",
    "\n",
    "# del pipeline.vae_encoder.session\n",
    "\n",
    "# prompt = \"sailing ship in storm by Leonardo da Vinci\"\n",
    "# image = pipeline(prompt, num_inference_steps=2).images[0]\n",
    "\n",
    "# pipeline.save_pretrained(\"./models/onnx/stable-diffusion-v1-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pipe = DiffusionPipeline.from_pretrained(\n",
    "#     \"./torch-stable-diffusion-v1-5\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     use_safetensors=True,\n",
    "# )\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "# image = pipe(prompt).images[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet2DConditionModel.from_pretrained(\"./exported-models/torch/stable-diffusion-v1-5/unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = torch.tensor([1, 2]).reshape(-1, 1).float()\n",
    "\n",
    "latent_model_input = torch.randn(2, 4, 64, 64)\n",
    "\n",
    "prompt_embeds = torch.randn(2, 77, 768)\n",
    "\n",
    "_ = unet(timestep=timesteps, sample=latent_model_input, encoder_hidden_states=prompt_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_diffusers.config import UNetOnnxConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_config = UNetOnnxConfig(unet.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample torch.Size([2, 4, 64, 64])\n",
      "timestep torch.Size([2, 1])\n",
      "encoder_hidden_states torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "inputs = onnx_config.generate_dummy_inputs()\n",
    "for key in inputs:\n",
    "    print(key, inputs[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 2.3.0+cu121\n",
      "/home/tran.duc.trungb/triton/triton-playground/02.build_tensorrt_from_sd/custom-diffusers/src/custom_diffusers/unet_2d_condition.py:1228: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if dim % default_overall_up_factor != 0:\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/models/downsampling.py:137: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/models/downsampling.py:146: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/models/upsampling.py:149: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/models/upsampling.py:165: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if hidden_states.shape[0] >= 64:\n",
      "/home/tran.duc.trungb/triton/triton-playground/02.build_tensorrt_from_sd/custom-diffusers/src/custom_diffusers/unet_2d_condition.py:1461: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not return_dict:\n",
      "Saving external data to one file...\n"
     ]
    }
   ],
   "source": [
    "onnx_path = Path(\"./exported-models/onnx/unet.onnx\")\n",
    "\n",
    "onnx_inputs, onnx_outputs = export(unet, onnx_config, onnx_path, onnx_config.DEFAULT_ONNX_OPSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': {0: 'batch_size', 1: 'num_channels', 2: 'height', 3: 'width'},\n",
       " 'timestep': {0: 'batch_size'},\n",
       " 'encoder_hidden_states': {0: 'batch_size', 1: 'sequence_length'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_config.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(onnx_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating ONNX model exported-models/onnx/unet.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (sample)\n",
      "\t- Validating ONNX Model output \"sample\":\n",
      "\t\t-[✓] (2, 4, 64, 64) matches (2, 4, 64, 64)\n",
      "\t\t-[✓] all values close (atol: 0.001)\n"
     ]
    }
   ],
   "source": [
    "from optimum.exporters.onnx import validate_model_outputs\n",
    "\n",
    "validate_model_outputs(\n",
    "    onnx_config, unet, onnx_path, onnx_outputs, onnx_config.ATOL_FOR_VALIDATION\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton-huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
