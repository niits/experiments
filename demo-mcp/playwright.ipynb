{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f452e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index-tools-mcp llama-index python-dotenv fastmcp -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b6a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container ID: d17b004f6f55d878175cde362d9a234e856016e277722b1d5bb2cd32a350e9c7\n"
     ]
    }
   ],
   "source": [
    "logs = !docker run -i -d --rm --init --pull=always -p 8931:8931 mcr.microsoft.com/playwright/mcp --port 8931\n",
    "container_id = logs[-1]\n",
    "\n",
    "print(\"Container ID:\", container_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bfe320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.workflow import Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d675433",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d098ec02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<llama_index.core.tools.function_tool.FunctionTool at 0x7787b1700ec0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b1a2b890>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b1a2b750>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b1634050>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b1637bb0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14dc290>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b149d150>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b149d260>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14a3250>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14a2d50>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787f05215e0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b163ea80>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14fbe70>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14fbcb0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14d5160>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b1742990>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b1742b10>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b162de90>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b162dff0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b0b74910>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b0b74f50>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14635c0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14631d0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b1462f00>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x7787b14634a0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcp_client = BasicMCPClient(\"http://localhost:8931/sse\")\n",
    "\n",
    "hero_mcp_tool_spec = McpToolSpec(\n",
    "    client=mcp_client,\n",
    ")\n",
    "\n",
    "tools = await hero_mcp_tool_spec.to_tool_list_async()\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86a018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector_agent = FunctionAgent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that can collect information from various sources.\",\n",
    ")\n",
    "\n",
    "ctx = Context(collector_agent)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7895e813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Here are some of the trending repositories on GitHub:\n",
      "\n",
      "1. **[All-Hands-AI / OpenHands](https://github.com/All-Hands-AI/OpenHands)**\n",
      "   - Description: üôå OpenHands: Code Less, Make More\n",
      "   - Stars: 54,926\n",
      "   - Forks: 6,189\n",
      "   - Language: Python\n",
      "\n",
      "2. **[appwrite / appwrite](https://github.com/appwrite/appwrite)**\n",
      "   - Description: The open-source Vercel alternative\n",
      "   - Stars: 49,645\n",
      "   - Forks: 4,370\n",
      "   - Language: TypeScript\n",
      "\n",
      "3. **[panaversity / learn-agentic-ai](https://github.com/panaversity/learn-agentic-ai)**\n",
      "   - Description: Learn Agentic AI using Dapr Agentic Cloud Ascent (DACA) Design Pattern and Agent-Native Cloud Technologies.\n",
      "   - Stars: 2,340\n",
      "   - Forks: 554\n",
      "   - Language: Jupyter Notebook\n",
      "\n",
      "4. **[microsoft / WSL](https://github.com/microsoft/WSL)**\n",
      "   - Description: Windows Subsystem for Linux\n",
      "   - Stars: 26,415\n",
      "   - Forks: 1,222\n",
      "   - Language: C++\n",
      "\n",
      "5. **[usebruno / bruno](https://github.com/usebruno/bruno)**\n",
      "   - Description: Opensource IDE For Exploring and Testing Api's (lightweight alternative to postman/insomnia)\n",
      "   - Stars: 33,944\n",
      "   - Forks: 1,610\n",
      "   - Language: JavaScript\n",
      "\n",
      "6. **[HeyPuter / puter](https://github.com/HeyPuter/puter)**\n",
      "   - Description: üåê The Internet OS! Free, Open-Source, and Self-Hostable.\n",
      "   - Stars: 32,054\n",
      "   - Forks: 2,377\n",
      "   - Language: JavaScript\n",
      "\n",
      "7. **[usememos / memos](https://github.com/usememos/memos)**\n",
      "   - Description: An open-source, lightweight note-taking solution.\n",
      "   - Stars: 40,770\n",
      "   - Forks: 2,884\n",
      "   - Language: Go\n",
      "\n",
      "8. **[modelcontextprotocol / registry](https://github.com/modelcontextprotocol/registry)**\n",
      "   - Description: A community driven registry service for Model Context Protocol (MCP) servers.\n",
      "   - Stars: 648\n",
      "   - Forks: 45\n",
      "   - Language: Go\n",
      "\n",
      "9. **[ZJU-LLMs / Foundations-of-LLMs](https://github.com/ZJU-LLMs/Foundations-of-LLMs)**\n",
      "   - Stars: 10,405\n",
      "   - Forks: 907\n",
      "\n",
      "10. **[virattt / ai-hedge-fund](https://github.com/virattt/ai-hedge-fund)**\n",
      "    - Description: An AI Hedge Fund Team\n",
      "    - Stars: 32,193\n",
      "    - Forks: 5,529\n",
      "    - Language: Python\n",
      "\n",
      "11. **[microsoft / vscode](https://github.com/microsoft/vscode)**\n",
      "    - Description: Visual Studio Code\n",
      "    - Stars: 172,043\n",
      "    - Forks: 32,509\n",
      "    - Language: TypeScript\n",
      "\n",
      "12. **[huggingface / huggingface.js](https://github.com/huggingface/huggingface.js)**\n",
      "    - Description: Utilities to use the Hugging Face Hub API\n",
      "    - Stars: 1,736\n",
      "    - Forks: 388\n",
      "    - Language: TypeScript\n",
      "\n",
      "These repositories are currently trending and showcase a variety of projects across different programming languages.\n"
     ]
    }
   ],
   "source": [
    "response = await collector_agent.run(\"L√™n trang github v√† l·∫•y trending repo\", ctx=ctx)\n",
    "print(\"Response:\")\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63057807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d17b004f6f55d878175cde362d9a234e856016e277722b1d5bb2cd32a350e9c7\n"
     ]
    }
   ],
   "source": [
    "!docker stop {container_id}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
